{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOZGww_uVRLA"
      },
      "source": [
        "#Facial Expression Recognition\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nljA0VHvaYLD"
      },
      "source": [
        "## Extract and Check Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xy0H9LFa0vv"
      },
      "source": [
        "import tarfile \n",
        "\n",
        "file_path = #.tar file path\n",
        "tar_file = tarfile.open(file_path, 'r')\n",
        "tar_file.extractall('/content/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "images = os.listdir('train images path')\n",
        "annots = os.listdir('train annotations path')"
      ],
      "metadata": {
        "id": "gS8ntrpwFG5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check random images\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "rand_index = random.randint(0, len(images))\n",
        "img = plt.imread('train_set/images/'+images[rand_index])\n",
        "plt.imshow(img)"
      ],
      "metadata": {
        "id": "76aGC7OIFUyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Lets format the data "
      ],
      "metadata": {
        "id": "gTvTn7sCbhMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# # define the image and annotation directories\n",
        "image_dir = '/content/train_set/images'\n",
        "annotation_dir = '/content/train_set/annotations'\n",
        "\n",
        "# #for test set\n",
        "# image_dir = '/content/val_set/images'\n",
        "# annotation_dir = '/content/val_set/annotations'\n",
        "\n",
        "\n",
        "\n",
        "# create a list of image filenames\n",
        "image_filenames = os.listdir(image_dir)\n",
        "\n",
        "# create a dictionary to store the annotations\n",
        "annotations = {}\n",
        "\n",
        "# iterate over the image filenames and load the corresponding annotations\n",
        "for image_filename in image_filenames:\n",
        "    # extract the image ID from the filename\n",
        "    image_id = os.path.splitext(image_filename)[0]\n",
        "    \n",
        "    # load the expression, arousal, and valence annotations for the image\n",
        "    exp_filename = os.path.join(annotation_dir, f'{image_id}_exp.npy')\n",
        "    aro_filename = os.path.join(annotation_dir, f'{image_id}_aro.npy')\n",
        "    val_filename = os.path.join(annotation_dir, f'{image_id}_val.npy')\n",
        "    exp = np.load(exp_filename)\n",
        "    aro = np.load(aro_filename)\n",
        "    val = np.load(val_filename)\n",
        "    \n",
        "    # store the annotations in the dictionary\n",
        "    annotations[image_id] = (exp, aro, val)\n",
        "    \n",
        "# create a list of image paths and their corresponding annotations\n",
        "image_paths = [os.path.join(image_dir, image_filename) for image_filename in image_filenames]\n",
        "annotations_list = [annotations[os.path.splitext(image_filename)[0]] for image_filename in image_filenames]"
      ],
      "metadata": {
        "id": "WyDiDu_t9ioW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a TensorFlow dataset\n",
        "dataset = tf.data.Dataset.from_tensor_slices((image_paths, annotations_list))"
      ],
      "metadata": {
        "id": "NxgyuSM8CuIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define a function to preprocess the images and annotations\n",
        "def preprocess_image(image_path, annotation):\n",
        "    # load the image\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "    \n",
        "    # preprocess the annotations\n",
        "    exp = tf.one_hot(int(annotation[0]), depth=8)\n",
        "    aro = float(annotation[1])\n",
        "    val = float(annotation[2])\n",
        "    \n",
        "    return image, {'category_output': exp, 'aro_out': aro, 'val_out': val}\n",
        "\n",
        "# apply the preprocessing function to the dataset\n",
        "dataset = dataset.map(preprocess_image)\n",
        "\n",
        "# split the dataset into training and validation sets \n",
        "train_dataset = dataset.take(200000)\n",
        "val_dataset = dataset.skip(200000)\n",
        "\n",
        "#for test set\n",
        "# test_set = dataset\n",
        "\n",
        "# define batch size and shuffle buffer size\n",
        "batch_size = 32\n",
        "shuffle_buffer_size = 10000\n",
        "\n",
        "# shuffle and batch the training dataset\n",
        "train_dataset = train_dataset.shuffle(buffer_size=shuffle_buffer_size)\n",
        "train_dataset = train_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# batch the validation dataset\n",
        "val_dataset = val_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "\n",
        "# for test set\n",
        "# test_dataset = test_set.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n"
      ],
      "metadata": {
        "id": "vdx0l5ydCq7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLU_uiA8p3Ar"
      },
      "source": [
        "train_dataset, val_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-PhvSAOvgPJ"
      },
      "source": [
        "##Set up Mixed Percision training\n",
        "\n",
        "It utilizes the combo of float16 AND float32 to increase the speed\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WY3Fw7kwJjG"
      },
      "source": [
        "#Turn on mixed precision training\n",
        "from tensorflow.keras import mixed_precision\n",
        "mixed_precision.set_global_policy(\"mixed_float16\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPiKsxeexTFs"
      },
      "source": [
        "##Create Feature Extraction Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Hr36HkGzM6t"
      },
      "source": [
        "#build the model\n",
        "from tensorflow.keras import layers\n",
        "#from tensorflow.keras.layers.experimental import preprocessig #if rescaling is needed\n",
        "\n",
        "#base model\n",
        "input_shape=(224,224,3)\n",
        "base_model= tf.keras.applications.EfficientNetB0(include_top=False)\n",
        "base_model.trainable=False\n",
        "#input layer\n",
        "inputs= tf.keras.layers.Input(shape=input_shape, name=\"input_layer\")\n",
        "#Note: EfficientNetBX has resscaling built in if not \n",
        "# x = preprocessing.rescaling(1./255)(x)\n",
        "\n",
        "x= base_model(inputs, training=False)\n",
        "\n",
        "x= layers.GlobalAveragePooling2D()(x)\n",
        "category_out=layers.Dense(8, activation='softmax', name='category_output')(x)\n",
        "arousal_out=layers.Dense(1, activation='relu', name='aro_out')(x)\n",
        "valance_out = layers.Dense(1, activation='relu', name='val_out')(x)\n",
        "\n",
        "outputs= [category_out, arousal_out, valance_out]\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "#compilation\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(), loss={'category_output': 'categorical_crossentropy', 'aro_out': 'mse', 'val_out': 'mse'},\n",
        "              metrics={'category_output': 'accuracy', 'aro_out': 'mae', 'val_out': 'mae'})\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wm1aDx2W2W--"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lI06P6uOKFT"
      },
      "source": [
        "##Fit the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_I43XElWPJaN"
      },
      "source": [
        "history_feature_extraction=model.fit(train_dataset,\n",
        "          steps_per_epoch=int(0.2*len(train_dataset)), #do not have compute resources\n",
        "          epochs=5,\n",
        "          validation_data=val_dataset,\\\n",
        "          validation_steps = int(0.2*len(val_dataset)),\n",
        "          callbacks=[model_checkpoint])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_dataset)"
      ],
      "metadata": {
        "id": "8QDaZTjkNPSV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation of EfficientNetB0"
      ],
      "metadata": {
        "id": "uOJkBB2ParDZ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aGcrCNwRkk-"
      },
      "source": [
        "results_feature_extract=model.evaluate(test_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prediction with EfficientNetB0"
      ],
      "metadata": {
        "id": "W-vuwJlLaumO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check random images\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "images = os.listdir('/content/val_set/images')\n",
        "annots = os.listdir('/content/val_set/annotations')\n",
        "\n",
        "rand_index = random.randint(0, len(images))\n",
        "exp_filename = images[rand_index].replace('.jpg', '_exp.npy')\n",
        "aro_filename = images[rand_index].replace('.jpg', '_aro.npy')\n",
        "val_filename = images[rand_index].replace('.jpg', '_val.npy')\n",
        "exp = np.load('/content/val_set/annotations/'+exp_filename)\n",
        "aro = np.load('/content/val_set/annotations/'+aro_filename)\n",
        "val = np.load('/content/val_set/annotations/'+val_filename)\n",
        "img = plt.imread('val_set/images/'+images[rand_index])\n",
        "preds = model.predict(np.expand_dims(img, 0))\n",
        "plt.imshow(img)\n",
        "plt.title(f'Orignal\\tExp {exp}, Aro {aro}, Val {val}\\nPredicted\\tExp {np.argmax(preds[0])}, Aro {preds[1]}, Val {preds[2]}')"
      ],
      "metadata": {
        "id": "D6em8Oa-MxNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a=model.predict(np.expand_dims(img, 0))\n",
        "np.argmax(a[0])"
      ],
      "metadata": {
        "id": "lK4ULug4Wfhh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## With ResNet BaseLine"
      ],
      "metadata": {
        "id": "WfKybdXZMBil"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#build the model\n",
        "from tensorflow.keras import layers\n",
        "#from tensorflow.keras.layers.experimental import preprocessig #if rescaling is needed\n",
        "\n",
        "#base model\n",
        "input_shape=(224,224,3)\n",
        "base_model= tf.keras.applications.resnet50.ResNet50(include_top=False)\n",
        "base_model.trainable=False\n",
        "#input layer\n",
        "inputs= tf.keras.layers.Input(shape=input_shape, name=\"input_layer\")\n",
        "\n",
        "x= base_model(inputs, training=False)\n",
        "\n",
        "x= layers.GlobalAveragePooling2D()(x)\n",
        "category_out=layers.Dense(8, activation='softmax',name='category_output')(x)\n",
        "arousal_out=layers.Dense(1, activation='relu', name='aro_out')(x)\n",
        "valance_out = layers.Dense(1, activation='relu', name='val_out')(x)\n",
        "\n",
        "outputs= [category_out, arousal_out, valance_out]\n",
        "model_res = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "#compilation\n",
        "model_res.compile(optimizer=tf.keras.optimizers.Adam(), loss={'category_output': 'categorical_crossentropy', 'aro_out': 'mse', 'val_out': 'mse'},\n",
        "              metrics={'category_output': 'accuracy', 'aro_out': 'mae', 'val_out': 'mae'})"
      ],
      "metadata": {
        "id": "QGheu8Zp98Ay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_res.summary()"
      ],
      "metadata": {
        "id": "0DCeEECqca2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_resnet=model_res.fit(train_dataset,\n",
        "          steps_per_epoch=int(0.2*len(train_dataset)), \n",
        "          epochs=5,\n",
        "          validation_data=val_dataset,\n",
        "          validation_steps = int(0.2*len(val_dataset))\n",
        "          )"
      ],
      "metadata": {
        "id": "NsRk9G5TZE5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation of ResNet"
      ],
      "metadata": {
        "id": "Or7uiTgxa6Qh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_feature_extract=model_res.evaluate(test_dataset)"
      ],
      "metadata": {
        "id": "Wc74mrJga5cU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhttYVb5hnwC"
      },
      "source": [
        "### Making Predictions with ResNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojHbL5PFqTjw"
      },
      "source": [
        "# check random images\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "images = os.listdir('/content/val_set/images')\n",
        "annots = os.listdir('/content/val_set/annotations')\n",
        "\n",
        "rand_index = random.randint(0, len(images))\n",
        "exp_filename = images[rand_index].replace('.jpg', '_exp.npy')\n",
        "aro_filename = images[rand_index].replace('.jpg', '_aro.npy')\n",
        "val_filename = images[rand_index].replace('.jpg', '_val.npy')\n",
        "exp = np.load('/content/val_set/annotations/'+exp_filename)\n",
        "aro = np.load('/content/val_set/annotations/'+aro_filename)\n",
        "val = np.load('/content/val_set/annotations/'+val_filename)\n",
        "img = plt.imread('val_set/images/'+images[rand_index])\n",
        "preds = model_res.predict(np.expand_dims(img, 0))\n",
        "plt.imshow(img)\n",
        "plt.title(f'Orignal\\tExp {exp}, Aro {aro}, Val {val}\\nPredicted\\tExp {np.argmax(preds[0])}, Aro {preds[1]}, Val {preds[2]}')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}